from pathlib import Path
from typing import Literal

import click
import dask.array as da
import numpy as np
import pandas as pd
import scipy.ndimage as ndi

from iohub import open_ome_zarr
from skimage.registration import phase_cross_correlation

from mantis.analysis.AnalysisSettings import ProcessingSettings


def estimate_shift(
    im0: np.ndarray, im1: np.ndarray, percent_overlap: float, direction: Literal["row", "col"]
):
    assert 0 <= percent_overlap <= 1, "percent_overlap must be between 0 and 1"
    assert direction in ["row", "col"], "direction must be either 'row' or 'col'"
    assert im0.shape == im1.shape, "Images must have the same shape"

    sizeY, sizeX = im0.shape[-2:]

    # TODO: there may be a one pixel error in the estimated shift
    if direction == "row":
        y_roi = int(sizeY * np.minimum(percent_overlap + 0.05, 1))
        shift, _, _ = phase_cross_correlation(
            im0[-y_roi:, :], im1[:y_roi, :], upsample_factor=10
        )
        shift[0] += sizeX - y_roi
    elif direction == "col":
        x_roi = int(sizeX * np.minimum(percent_overlap + 0.05, 1))
        shift, _, _ = phase_cross_correlation(
            im0[:, -x_roi:], im1[:, :x_roi], upsample_factor=10
        )
        shift[1] += sizeY - x_roi

    # TODO: we shouldn't need to flip the order
    return shift[::-1]


def get_grid_rows_cols(dataset_path: str):
    grid_rows = set()
    grid_cols = set()

    with open_ome_zarr(dataset_path) as dataset:

        _, well = next(dataset.wells())
        for position_name, _ in well.positions():
            fov_name = Path(position_name).parts[-1]
            grid_rows.add(fov_name[3:])  # 1-Pos<COL>_<ROW> syntax
            grid_cols.add(fov_name[:3])

    return sorted(grid_rows), sorted(grid_cols)


def get_stitch_output_shape(n_rows, n_cols, sizeY, sizeX, col_translation, row_translation):
    # TODO: test with non-square images and non-square grid
    global_translation = (
        np.ceil(np.abs(np.minimum(row_translation[0] * (n_rows - 1), 0))).astype(int),
        np.ceil(np.abs(np.minimum(col_translation[1] * (n_cols - 1), 0))).astype(int),
    )
    xy_output_shape = (
        np.ceil(
            sizeY
            + col_translation[1] * (n_cols - 1)
            + row_translation[1] * (n_rows - 1)
            + global_translation[1]
        ).astype(int),
        np.ceil(
            sizeX
            + col_translation[0] * (n_cols - 1)
            + row_translation[0] * (n_rows - 1)
            + global_translation[0]
        ).astype(int),
    )
    return xy_output_shape, global_translation


def get_image_shift(col_idx, row_idx, col_translation, row_translation, global_translation):
    return (
        col_translation[1] * col_idx + row_translation[1] * row_idx + global_translation[1],
        col_translation[0] * col_idx + row_translation[0] * row_idx + global_translation[0],
    )


def shift_image(
    image: np.ndarray,
    output_shape: tuple[float, float],
    shift: tuple[float, float],
    verbose: bool = False,
) -> np.ndarray:
    ndims = image.ndim
    sizeY, sizeX = image.shape[-2:]

    if verbose:
        print(f"Shifting image by {shift}")
    output = np.zeros(output_shape, dtype=np.float32)
    output[:sizeY, :sizeX] = np.squeeze(image)
    output = ndi.shift(output, shift, order=0)

    if ndims == 2:
        return output
    # deal with CZYX arrays in mantis pipeline
    elif ndims == 4:
        return output[np.newaxis, np.newaxis, :, :]


def stitch_images(
    data_array: np.ndarray,
    total_translation: dict[str : tuple[float, float]] = None,
    percent_overlap: float = None,
    col_translation: float | tuple[float, float] = None,
    row_translation: float | tuple[float, float] = None,
) -> np.ndarray:
    """
    Stitch an array of 2D images together to create a larger composite image.

    Args:
        data_array (np.ndarray):
            The data array to with shape (ROWS, COLS, Y, X) that will be stitched. Call this function multiple
            times to stitch multiple channels, slices, or time points.
        total_translation (dict[str: tuple[float, float]], optional):
            Shift to be applied to each fov, given as {fov: (y_shift, x_shift)}. Defaults to None.
        percent_overlap (float, optional):
            The percentage of overlap between adjacent images. Must be between 0 and 1. Defaults to None.
        col_translation (float | tuple[float, float], optional):
            The translation distance in pixels in the column direction. Can be a single value or a tuple
            of (x_translation, y_translation) when moving across columns. Defaults to None.
        row_translation (float | tuple[float, float], optional):
            See col_translation. Defaults to None.

    Returns:
        np.ndarray: The stitched composite 2D image

    Raises:
        AssertionError: If percent_overlap is not between 0 and 1.

    """

    n_rows, n_cols, sizeY, sizeX = data_array.shape

    if total_translation is None:
        if percent_overlap is not None:
            assert 0 <= percent_overlap <= 1, "percent_overlap must be between 0 and 1"
            col_translation = sizeX * (1 - percent_overlap)
            row_translation = sizeY * (1 - percent_overlap)
        if not isinstance(col_translation, tuple):
            col_translation = (col_translation, 0)
        if not isinstance(row_translation, tuple):
            row_translation = (0, row_translation)
        xy_output_shape, global_translation = get_stitch_output_shape(
            n_rows, n_cols, sizeY, sizeX, col_translation, row_translation
        )
    else:
        df = pd.DataFrame.from_dict(
            total_translation, orient="index", columns=["shift-y", "shift-x"]
        )
        xy_output_shape = (
            np.ceil(df["shift-y"].max() + sizeY).astype(int),
            np.ceil(df["shift-x"].max() + sizeX).astype(int),
        )
    stitched_array = np.zeros(xy_output_shape, dtype=np.float32)

    for row_idx in range(n_rows):
        for col_idx in range(n_cols):
            image = data_array[row_idx, col_idx]

            if total_translation is None:
                shift = get_image_shift(
                    col_idx, row_idx, col_translation, row_translation, global_translation
                )
            else:
                shift = total_translation[f"{col_idx:03d}{row_idx:03d}"]

            warped_image = shift_image(image, xy_output_shape, shift)
            overlap = np.logical_and(stitched_array, warped_image)
            stitched_array[:, :] += warped_image
            stitched_array[overlap] /= 2  # average blending in the overlapping region

    return stitched_array


def process_dataset(
    data_array: np.ndarray | da.Array,
    settings: ProcessingSettings,
    verbose: bool = True,
) -> np.ndarray:
    if settings:
        if settings.flipud:
            if verbose:
                click.echo("Flipping data array up-down")
            if isinstance(data_array, np.ndarray):
                data_array = np.flip(data_array, axis=-2)
            elif isinstance(data_array, da.Array):
                data_array = da.flip(data_array, axis=-2)
        if settings.fliplr:
            if verbose:
                click.echo("Flipping data array left-right")
            if isinstance(data_array, np.ndarray):
                data_array = np.flip(data_array, axis=-1)
            elif isinstance(data_array, da.Array):
                data_array = da.flip(data_array, axis=-1)

    return data_array


def _preprocess_and_shift(
    image, settings: ProcessingSettings, output_shape, shift_x, shift_y, verbose=True
):
    return shift_image(
        process_dataset(image, settings, verbose), output_shape, [shift_y, shift_x], verbose
    )


def _stitch_shifted_store(
    input_data_path, output_data_path, settings: ProcessingSettings, verbose=True
):
    click.echo(f'Stitching zarr store: {input_data_path}')
    with open_ome_zarr(input_data_path, mode="r") as input_dataset:
        for well_name, well in input_dataset.wells():
            if verbose:
                click.echo(f'Processing well {well_name}')
            dask_array = da.stack([da.from_zarr(pos.data) for _, pos in well.positions()])

            # Average blending
            array_sum = dask_array.sum(axis=0)
            array_bool_sum = (dask_array != 0).sum(axis=0)
            array_bool_sum[array_bool_sum == 0] = 1
            stitched_array = array_sum / array_bool_sum

            # Postprocessing
            stitched_array = process_dataset(stitched_array, settings, verbose)

            # Save stitched array
            with open_ome_zarr(
                Path(output_data_path, well_name, '0'), mode="a"
            ) as output_image:
                da.to_zarr(stitched_array, output_image['0'])
